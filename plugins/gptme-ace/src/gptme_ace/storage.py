#!/usr/bin/env python3
"""ACE Insight Storage System.

Stores insights from Generator and Reflector agents with metadata tracking
and conversion status to lessons. Part of Phase 2.3 of ACE implementation.

This module provides persistent storage for insights generated by ACE agents,
maintaining an index for quick access and supporting status tracking through
the insight lifecycle (pending → approved/rejected → converted to lesson).

Storage Structure:
    workspace/insights/
        raw/           - Raw insights from Generator agent
        refined/       - Refined insights from Reflector agent
        index.json     - Fast lookup index with statistics

Example:
    Store a raw insight::

        storage = InsightStorage()
        insight_id = storage.store_raw_insight(
            category="performance",
            title="Batch API calls improve throughput",
            description="...",
            evidence=["session1", "session2"],
            confidence=0.85,
            source_sessions=["session1", "session2"]
        )

    List pending insights::

        insights = storage.list_insights(status="pending")
        for insight in insights:
            print(f"{insight['title']} - {insight['status']}")
"""

import hashlib
import json
from dataclasses import asdict, dataclass
from datetime import datetime
from pathlib import Path
from typing import Any, List


@dataclass
class InsightMetadata:
    """Metadata for stored insights.

    Tracks the lifecycle of an insight from creation through review and
    potential conversion to a lesson.

    Attributes:
        insight_id: Unique hash-based ID derived from content.
        created_at: ISO 8601 timestamp of creation (UTC).
        source_agent: Which agent created it - "generator" or "reflector".
        status: Current status - "pending", "approved", "rejected", or "converted".
        converted_to_lesson: Path to lesson file if converted, None otherwise.
        reviewed_by: Who reviewed the insight (human username or "auto"), or None.
        reviewed_at: ISO 8601 timestamp of review (UTC), or None if not reviewed.
    """

    insight_id: str  # Unique hash-based ID
    created_at: str  # ISO timestamp
    source_agent: str  # generator or reflector
    status: str  # pending, approved, rejected, converted
    converted_to_lesson: str | None = None  # Lesson file if converted
    reviewed_by: str | None = None  # Who reviewed (human or auto)
    reviewed_at: str | None = None  # When reviewed


@dataclass
class StoredInsight:
    """Complete insight with metadata for storage.

    Combines the insight content from Generator/Reflector agents with
    storage metadata for persistence and tracking.

    Attributes:
        category: Insight category (e.g., "performance", "workflow", "tool-usage").
        title: Brief descriptive title of the insight.
        description: Detailed explanation of the insight.
        evidence: List of supporting evidence (session IDs, log excerpts, etc.).
        confidence: Confidence score 0.0-1.0 indicating insight reliability.
        source_sessions: List of session IDs where pattern was observed.
        metadata: Storage and lifecycle metadata (InsightMetadata object).
        refinement_notes: What the Reflector agent changed/improved (optional).
        pattern_type: Type of pattern - "success", "failure", "recurring", "emergent" (optional).
    """

    # Core insight data (from Generator/Reflector)
    category: str
    title: str
    description: str
    evidence: List[str]
    confidence: float
    source_sessions: List[str]

    # Storage metadata
    metadata: InsightMetadata

    # Optional refinement data (from Reflector)
    refinement_notes: str | None = None
    pattern_type: str | None = None  # success, failure, recurring, emergent


class InsightStorage:
    """Manages storage and retrieval of insights.

    Provides a complete CRUD interface for insights, maintaining both
    individual JSON files and a centralized index for fast querying.

    Attributes:
        workspace_root: Root directory of the workspace.
        insights_dir: Directory for all insight storage (workspace/insights).
        raw_dir: Storage for raw insights from Generator (insights/raw).
        refined_dir: Storage for refined insights from Reflector (insights/refined).
        index_file: JSON index file for fast lookups (insights/index.json).
    """

    def __init__(self, workspace_root: Path = Path.home() / "bob"):
        self.workspace_root = workspace_root
        self.insights_dir = workspace_root / "insights"
        self.raw_dir = self.insights_dir / "raw"
        self.refined_dir = self.insights_dir / "refined"
        self.index_file = self.insights_dir / "index.json"

        # Ensure directories exist
        self.raw_dir.mkdir(parents=True, exist_ok=True)
        self.refined_dir.mkdir(parents=True, exist_ok=True)

    def _generate_id(self, insight_data: dict) -> str:
        """Generate unique ID from insight content.

        Creates a deterministic hash-based ID from title, category, and first
        source session to ensure insights with same content get same ID.

        Args:
            insight_data: Dict with 'title', 'category', and 'source_sessions' keys.

        Returns:
            16-character hexadecimal hash string.
        """
        # Use title + category + first source session for ID
        content = f"{insight_data['title']}:{insight_data['category']}:{insight_data.get('source_sessions', [''])[0]}"
        return hashlib.sha256(content.encode()).hexdigest()[:16]

    def _load_index(self) -> dict[str, Any]:
        """Load the insight index."""
        if self.index_file.exists():
            data: dict[str, Any] = json.loads(self.index_file.read_text())
            return data
        return {"raw": {}, "refined": {}, "statistics": {"total": 0, "by_status": {}}}

    def _save_index(self, index: dict) -> None:
        """Save the insight index."""
        self.index_file.write_text(json.dumps(index, indent=2))

    def store_raw_insight(
        self,
        category: str,
        title: str,
        description: str,
        evidence: List[str],
        confidence: float,
        source_sessions: List[str],
    ) -> str:
        """
        Store raw insight from Generator.

        Returns:
            insight_id: Unique ID of stored insight
        """
        # Generate ID
        insight_data = {
            "title": title,
            "category": category,
            "source_sessions": source_sessions,
        }
        insight_id = self._generate_id(insight_data)

        # Create metadata
        metadata = InsightMetadata(
            insight_id=insight_id,
            created_at=datetime.utcnow().isoformat() + "Z",
            source_agent="generator",
            status="pending",
        )

        # Create stored insight
        stored = StoredInsight(
            category=category,
            title=title,
            description=description,
            evidence=evidence,
            confidence=confidence,
            source_sessions=source_sessions,
            metadata=metadata,
        )

        # Save to file
        insight_file = self.raw_dir / f"{insight_id}.json"
        insight_file.write_text(json.dumps(asdict(stored), indent=2))

        # Update index
        index = self._load_index()
        index["raw"][insight_id] = {
            "title": title,
            "category": category,
            "status": "pending",
            "created_at": metadata.created_at,
            "file": str(insight_file.relative_to(self.workspace_root)),
        }
        index["statistics"]["total"] = index["statistics"].get("total", 0) + 1
        index["statistics"]["by_status"]["pending"] = (
            index["statistics"]["by_status"].get("pending", 0) + 1
        )
        self._save_index(index)

        return insight_id

    def store_refined_insight(
        self,
        raw_insight_id: str,
        category: str,
        title: str,
        description: str,
        evidence: List[str],
        confidence: float,
        source_sessions: List[str],
        refinement_notes: str,
        pattern_type: str,
    ) -> str:
        """
        Store refined insight from Reflector.

        Args:
            raw_insight_id: ID of original raw insight
            Other params: Refined insight data
            refinement_notes: What Reflector changed/improved
            pattern_type: success, failure, recurring, emergent

        Returns:
            insight_id: Unique ID of refined insight
        """
        # Generate ID (will be different from raw if refined)
        insight_data = {
            "title": title,
            "category": category,
            "source_sessions": source_sessions,
        }
        insight_id = self._generate_id(insight_data)

        # Create metadata
        metadata = InsightMetadata(
            insight_id=insight_id,
            created_at=datetime.utcnow().isoformat() + "Z",
            source_agent="reflector",
            status="pending",
        )

        # Create stored insight with refinement data
        stored = StoredInsight(
            category=category,
            title=title,
            description=description,
            evidence=evidence,
            confidence=confidence,
            source_sessions=source_sessions,
            metadata=metadata,
            refinement_notes=refinement_notes,
            pattern_type=pattern_type,
        )

        # Save to file
        insight_file = self.refined_dir / f"{insight_id}.json"
        insight_file.write_text(json.dumps(asdict(stored), indent=2))

        # Update index
        index = self._load_index()
        index["refined"][insight_id] = {
            "title": title,
            "category": category,
            "status": "pending",
            "created_at": metadata.created_at,
            "raw_insight_id": raw_insight_id,
            "pattern_type": pattern_type,
            "file": str(insight_file.relative_to(self.workspace_root)),
        }
        index["statistics"]["total"] = index["statistics"].get("total", 0) + 1
        index["statistics"]["by_status"]["pending"] = (
            index["statistics"]["by_status"].get("pending", 0) + 1
        )
        self._save_index(index)

        return insight_id

    def get_insight(
        self, insight_id: str, source_agent: str = "raw"
    ) -> StoredInsight | None:
        """
        Retrieve insight by ID.

        Args:
            insight_id: ID of insight to retrieve
            source_agent: 'raw' or 'refined'

        Returns:
            StoredInsight or None if not found
        """
        insight_dir = self.raw_dir if source_agent == "raw" else self.refined_dir
        insight_file = insight_dir / f"{insight_id}.json"

        if not insight_file.exists():
            return None

        data = json.loads(insight_file.read_text())
        # Deserialize nested InsightMetadata dataclass
        if "metadata" in data and isinstance(data["metadata"], dict):
            data["metadata"] = InsightMetadata(**data["metadata"])
        return StoredInsight(**data)

    def update_status(
        self,
        insight_id: str,
        source_agent: str,
        new_status: str,
        reviewer: str | None = None,
        converted_to_lesson: str | None = None,
    ) -> None:
        """
        Update insight status.

        Args:
            insight_id: ID of insight
            source_agent: 'raw' or 'refined'
            new_status: pending, approved, rejected, converted
            reviewer: Who reviewed (optional)
            converted_to_lesson: Lesson file if converted (optional)
        """
        # Load insight
        insight = self.get_insight(insight_id, source_agent)
        if not insight:
            raise ValueError(f"Insight {insight_id} not found")

        # Update metadata
        old_status = insight.metadata.status
        insight.metadata.status = new_status
        if reviewer:
            insight.metadata.reviewed_by = reviewer
            insight.metadata.reviewed_at = datetime.utcnow().isoformat() + "Z"
        if converted_to_lesson:
            insight.metadata.converted_to_lesson = converted_to_lesson

        # Save updated insight
        insight_dir = self.raw_dir if source_agent == "raw" else self.refined_dir
        insight_file = insight_dir / f"{insight_id}.json"
        insight_file.write_text(json.dumps(asdict(insight), indent=2))

        # Update index
        index = self._load_index()
        agent_key = source_agent
        if insight_id in index[agent_key]:
            index[agent_key][insight_id]["status"] = new_status

            # Update statistics
            stats = index["statistics"]["by_status"]
            stats[old_status] = max(0, stats.get(old_status, 0) - 1)
            stats[new_status] = stats.get(new_status, 0) + 1

        self._save_index(index)

    def list_insights(
        self,
        source_agent: str = "raw",
        status: str | None = None,
        category: str | None = None,
    ) -> List[dict]:
        """
        List insights with optional filtering.

        Args:
            source_agent: 'raw' or 'refined'
            status: Filter by status (optional)
            category: Filter by category (optional)

        Returns:
            List of insight summary dicts
        """
        index = self._load_index()
        insights = index.get(source_agent, {})

        results = []
        for insight_id, info in insights.items():
            # Apply filters
            if status and info.get("status") != status:
                continue
            if category and info.get("category") != category:
                continue

            results.append(
                {
                    "insight_id": insight_id,
                    "title": info.get("title"),
                    "category": info.get("category"),
                    "status": info.get("status"),
                    "created_at": info.get("created_at"),
                    "file": info.get("file"),
                }
            )

        # Sort by creation time (newest first)
        results.sort(key=lambda x: x["created_at"], reverse=True)
        return results

    def get_statistics(self) -> dict:
        """Get storage statistics.

        Returns:
            Dict with keys:
                - total_insights: Total count across all agents
                - by_status: Dict mapping status to count
                - by_agent: Dict mapping agent type ("raw"/"refined") to count
        """
        index = self._load_index()
        return {
            "total_insights": index["statistics"].get("total", 0),
            "by_status": index["statistics"].get("by_status", {}),
            "by_agent": {
                "raw": len(index.get("raw", {})),
                "refined": len(index.get("refined", {})),
            },
        }


def main():
    """CLI interface for insight storage."""
    import argparse

    parser = argparse.ArgumentParser(description="ACE Insight Storage System")
    parser.add_argument("command", choices=["list", "show", "stats", "update-status"])
    parser.add_argument("--agent", choices=["raw", "refined"], default="raw")
    parser.add_argument("--id", help="Insight ID")
    parser.add_argument("--status", help="Filter by status")
    parser.add_argument("--category", help="Filter by category")
    parser.add_argument("--new-status", help="New status for update")
    parser.add_argument("--reviewer", help="Reviewer name")

    args = parser.parse_args()

    storage = InsightStorage()

    if args.command == "list":
        insights = storage.list_insights(
            source_agent=args.agent, status=args.status, category=args.category
        )
        print(f"Found {len(insights)} insights:")
        for insight in insights:
            print(f"  {insight['insight_id']}: {insight['title']}")
            print(f"    Category: {insight['category']}, Status: {insight['status']}")
            print(f"    Created: {insight['created_at']}")
            print()

    elif args.command == "show":
        if not args.id:
            print("Error: --id required for show command")
            return
        maybe_insight = storage.get_insight(args.id, args.agent)
        if maybe_insight is not None:
            print(json.dumps(asdict(maybe_insight), indent=2))
        else:
            print(f"Insight {args.id} not found")

    elif args.command == "stats":
        stats = storage.get_statistics()
        print("Storage Statistics:")
        print(f"  Total insights: {stats['total_insights']}")
        print("  By agent:")
        for agent, count in stats["by_agent"].items():
            print(f"    {agent}: {count}")
        print("  By status:")
        for status, count in stats["by_status"].items():
            print(f"    {status}: {count}")

    elif args.command == "update-status":
        if not args.id or not args.new_status:
            print("Error: --id and --new-status required")
            return
        storage.update_status(
            args.id, args.agent, args.new_status, reviewer=args.reviewer
        )
        print(f"Updated {args.id} to status: {args.new_status}")


if __name__ == "__main__":
    main()
