Metadata-Version: 2.4
Name: gptme-retrieval
Version: 0.1.0
Summary: Retrieval hook plugin for gptme - automatic context retrieval using qmd or other backends
License: MIT
Requires-Python: >=3.10
Description-Content-Type: text/markdown
Requires-Dist: gptme
Provides-Extra: dev
Requires-Dist: pytest>=7.0; extra == "dev"
Requires-Dist: pytest-cov>=4.0; extra == "dev"
Requires-Dist: mypy>=1.0; extra == "dev"

# gptme-retrieval

Automatic context retrieval plugin for gptme.

This plugin adds a STEP_PRE hook that automatically retrieves relevant context before each LLM step, using backends like [qmd](https://github.com/ErikBjare/qmd) for semantic and keyword search.

## Installation

```bash
# Install the plugin
pip install -e plugins/gptme-retrieval

# Make sure qmd is installed (for default backend)
cargo install qmd
```

## Configuration

Configure in your `gptme.toml`:

```toml
[plugin.retrieval]
enabled = true           # Enable/disable retrieval (default: true)
backend = "qmd"          # Backend: "qmd", "gptme-rag", "grep", or custom command
mode = "vsearch"         # qmd mode: "search" (BM25), "vsearch" (semantic), "query" (hybrid)
max_results = 5          # Maximum results to inject (default: 5)
threshold = 0.3          # Minimum score threshold (default: 0.3)
collections = []         # Optional: filter by collection names
inject_as = "system"     # "system" for visible, "hidden" for background context
```

## How It Works

1. **STEP_PRE Hook**: Before each LLM generation step, the plugin extracts the last user message
2. **Retrieval**: Queries the configured backend with the user's message text
3. **Injection**: Adds retrieved context as a system message

## Backends

### qmd (default)

Uses [qmd](https://github.com/ErikBjare/qmd) for retrieval. Supports three modes:
- `search`: BM25 keyword search
- `vsearch`: Semantic/vector search
- `query`: Hybrid search combining both

### gptme-rag

Uses [gptme-rag](https://github.com/gptme/gptme-rag) for retrieval. Experimental but integrates well with gptme:

```toml
[plugin.retrieval]
backend = "gptme-rag"
```

Install with: `pipx install gptme-rag`

Note: gptme-rag is currently experimental and may have issues.

### grep

Simple grep-based fallback for basic keyword matching.

### Custom

Any command that accepts a query and outputs JSON can be used:

```toml
[plugin.retrieval]
backend = "my-search --json"
```

## Indexing Conversations

To index gptme conversations with qmd:

```bash
# Extract user/assistant messages (skip system)
jq 'select(.role != "system") | {role, content}' ~/.local/share/gptme/logs/*/conversation.jsonl > filtered.jsonl

# Index with qmd
qmd index filtered.jsonl --collection conversations
```

## Related

- [Issue #59](https://github.com/gptme/gptme/issues/59) - Original feature discussion
- [PR #1197](https://github.com/gptme/gptme/pull/1197) - `[plugin.*]` config namespace support
- [qmd](https://github.com/tobi/qmd) - The recommended retrieval backend
